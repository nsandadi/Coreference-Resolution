{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TestGenderBias_GAP_DPR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOewdvxf2Dd3BLFyHAIPEpn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2b6e1209d6c45349e7fd9f5a35e3aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_332bea19350c479f9499cdb2b41a3b49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9410c0b0e8a44db79b8bc9ebeae04738",
              "IPY_MODEL_a014b7927ee641dc9b2f6505b5b6a14c"
            ]
          }
        },
        "332bea19350c479f9499cdb2b41a3b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9410c0b0e8a44db79b8bc9ebeae04738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42a4ed62f3564979a7ac3e5ac9a1a07c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 474,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 474,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_871dc95eb0ae424d8417a3a26fe2b037"
          }
        },
        "a014b7927ee641dc9b2f6505b5b6a14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_045b8cc8e4024a45b7c1e57142785aab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 474/474 [00:42&lt;00:00, 11.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3899e5e3b7242ff99144c85370b9fef"
          }
        },
        "42a4ed62f3564979a7ac3e5ac9a1a07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "871dc95eb0ae424d8417a3a26fe2b037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "045b8cc8e4024a45b7c1e57142785aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3899e5e3b7242ff99144c85370b9fef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aacbe678df7c40ac95c1b1f6cbfc1775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3151dfcf0d2b4e3c9eb318606e7a5f07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2172e6af276841aea9b6a19ed4cb6bc1",
              "IPY_MODEL_53965f3d6e7a40e1b547bee5ac3719fa"
            ]
          }
        },
        "3151dfcf0d2b4e3c9eb318606e7a5f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2172e6af276841aea9b6a19ed4cb6bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ca47750d3f64a36951ee8a4a96f59d1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1425950275,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1425950275,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9510b14501264bde9886620c687b5867"
          }
        },
        "53965f3d6e7a40e1b547bee5ac3719fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_869ad79d12754745a0bbf631dde8f3e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.43G/1.43G [00:41&lt;00:00, 34.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_723a97bf711d44df913f338e5c2e7047"
          }
        },
        "8ca47750d3f64a36951ee8a4a96f59d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9510b14501264bde9886620c687b5867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "869ad79d12754745a0bbf631dde8f3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "723a97bf711d44df913f338e5c2e7047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cdf0d97c60d47a6b25e5748563e2339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d26beb49a084ba08929e59ca0bafabd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_866eb0a75bf84e958ec8c1ba9301a2db",
              "IPY_MODEL_e0525b20c289424c9828404f2dde2315"
            ]
          }
        },
        "4d26beb49a084ba08929e59ca0bafabd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "866eb0a75bf84e958ec8c1ba9301a2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b621278be4f9440f91bd410441a62466",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c508104f93640d38971517aa8bd75f7"
          }
        },
        "e0525b20c289424c9828404f2dde2315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7beaa0c7176047a4946fe03ee9e85e61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 884kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27ecf9dbdbbe4caba9031502604b876a"
          }
        },
        "b621278be4f9440f91bd410441a62466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c508104f93640d38971517aa8bd75f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7beaa0c7176047a4946fe03ee9e85e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27ecf9dbdbbe4caba9031502604b876a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dad18441d20a4964baa180426ef6bb59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d94d3d63e77040cfb2054699b54db8da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_39bb0949d0c54514a2c045f0f5559dc8",
              "IPY_MODEL_18812da6dea549c7adbe514ba67b0097"
            ]
          }
        },
        "d94d3d63e77040cfb2054699b54db8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39bb0949d0c54514a2c045f0f5559dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1201329896b0412da963b67f5f6061a6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cea86daba2bb458f826d216d64b46a30"
          }
        },
        "18812da6dea549c7adbe514ba67b0097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1287b00f9a9f4277aeabd10e7633addb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:01&lt;00:00, 298kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8575cd4d55ce427cb5cb7f8f9ed427bf"
          }
        },
        "1201329896b0412da963b67f5f6061a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cea86daba2bb458f826d216d64b46a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1287b00f9a9f4277aeabd10e7633addb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8575cd4d55ce427cb5cb7f8f9ed427bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsandadi/Coreference-Resolution/blob/main/TestGenderBias_GAP_DPR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpzqrDI6iQju"
      },
      "source": [
        "## Test for Gender Bias\n",
        "### BERT, RoBERTa, CorefRoBERTa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OiD9POtiXcO"
      },
      "source": [
        "## Install Transformers library from Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT2LelAsRXpZ",
        "outputId": "410082b6-fea9-4993-da23-c4a1bff9fd2d"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-xtsunqqo\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-xtsunqqo\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 15.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.0.1)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.6.0.dev0-cp37-none-any.whl size=2090005 sha256=e56af5b71cd70e1cdda23fcdab6bbe7ec2392edb6855c228a03fc1e65b66be68\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w743d66k/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "Successfully built transformers\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=5a99dd66edd2df2435eaaa7cc025682bd53e2540a87548daf5b65b4aa0686923\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.6.0.dev0\n",
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 13.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.1+cu101)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/79/64c0815cbe8c6abd7fe5525ec37a2689d3cf10e387629ba4a6e44daff6d0/boto3-1.17.49-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 21.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 7.6MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.49\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/59/6e28ce58206039ad2592992b75ee79a8f9dbc902a9704373ddacc4f96300/botocore-1.20.49-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.4MB 17.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.49->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.49->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.49 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.17.49 botocore-1.20.49 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXkB7Sb9ib7Y"
      },
      "source": [
        "## Import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvwm9_oYRc8z",
        "outputId": "ad819bd6-8cd2-4458-a604-cd5d3a7f95c0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler, BatchSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import re\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from copy import deepcopy\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "import os\n",
        "import timeit\n",
        "\n",
        "## Download packages for GPU\n",
        "print('installing apex')\n",
        "os.system('git clone -q https://github.com/NVIDIA/apex.git')\n",
        "os.system('pip install -q --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex/')\n",
        "os.system('rm -rf apex')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "installing apex\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vhnKwamiiZy"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-YczPmxSpIL",
        "outputId": "632420fe-d306-4e40-9880-8a538f18241c"
      },
      "source": [
        "from google.colab import drive\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "drive.mount('/contents/')\n",
        "\n",
        "# Load data from drive\n",
        "winograd_train = pd.read_csv('/contents/My Drive/Winograd/winograd_train.csv')\n",
        "winograd_val = pd.read_csv('/contents/My Drive/Winograd/winograd_dev.csv')\n",
        "winograd_test = pd.read_csv('/contents/My Drive/Winograd/winograd_test.csv')\n",
        "\n",
        "print(\"Training data has\", len(winograd_train), \"records.\")\n",
        "print(\"Validation data has\", len(winograd_val), \"records.\")\n",
        "print(\"Test data has\", len(winograd_test), \"records.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /contents/\n",
            "Training data has 564 records.\n",
            "Validation data has 282 records.\n",
            "Test data has 282 records.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPvOX4GF0i4E"
      },
      "source": [
        "# ## Combining winograd train, val & test dataset to test set\n",
        "# gender_pronouns = ['she','her','hers','She','Her','Hers','he','him','his','He','Him','His']\n",
        "# winograd_test = winograd_test[winograd_test.Pronoun.astype(str).isin(gender_pronouns)]\n",
        "# winograd_train = winograd_train[winograd_train.Pronoun.astype(str).isin(gender_pronouns)]\n",
        "# winograd_val = winograd_val[winograd_val.Pronoun.astype(str).isin(gender_pronouns)]\n",
        "# winograd_data = pd.concat([winograd_train, winograd_val, winograd_test])\n",
        "# winograd_data = winograd_data.reset_index(drop=True)\n",
        "\n",
        "# # Adding ID column\n",
        "# winograd_data['ID'] = winograd_data.index \n",
        "# winograd_data['ID'] = winograd_data.ID+1\n",
        "# winograd_data['ID'] = 'test-' + winograd_data['ID'].astype(str)\n",
        "\n",
        "# # Reorder columns\n",
        "# cols = winograd_data.columns.tolist()\n",
        "# cols = cols[-1:] + cols[:-1]\n",
        "# winograd_data = winograd_data[cols]\n",
        "# print(\"Dataset has\",len(winograd_data),\"records\")\n",
        "# winograd_data.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKWrEnJ3S6Ia",
        "outputId": "7e92709a-39fa-4f25-910f-70936cda179b"
      },
      "source": [
        "winograd_train['ID'] = winograd_train.index \n",
        "winograd_train['ID'] = winograd_train.ID+1\n",
        "winograd_train['ID'] = 'development-' + winograd_train['ID'].astype(str)\n",
        "\n",
        "winograd_val['ID'] = winograd_val.index \n",
        "winograd_val['ID'] = winograd_val.ID+1\n",
        "winograd_val['ID'] = 'validation-' + winograd_val['ID'].astype(str)\n",
        "\n",
        "winograd_test['ID'] = winograd_test.index \n",
        "winograd_test['ID'] = winograd_test.ID+1\n",
        "winograd_test['ID'] = 'test-' + winograd_test['ID'].astype(str)\n",
        "\n",
        "print(\"Training data has\", len(winograd_train), \"records.\")\n",
        "print(\"Validation data has\", len(winograd_val), \"records.\")\n",
        "print(\"Test data has\", len(winograd_test), \"records.\")\n",
        "\n",
        "# # Concatenate train, validation and test datasets\n",
        "# winograd_data = pd.concat([winograd_train, winograd_val])\n",
        "# winograd_data = winograd_data.reset_index(drop=True)\n",
        "# print(\"Winograd data has\", len(winograd_data), \"records.\")\n",
        "\n",
        "# # Reorder columns\n",
        "# cols = winograd_data.columns.tolist()\n",
        "# cols = cols[-1:] + cols[:-1]\n",
        "# winograd_data = winograd_data[cols]\n",
        "# winograd_data.head()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data has 564 records.\n",
            "Validation data has 282 records.\n",
            "Test data has 282 records.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8PmuDv7wHkV",
        "outputId": "4459cf5e-3ef9-4357-c792-4ebad09c6a8f"
      },
      "source": [
        "os.system('wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-development.tsv -q')\n",
        "os.system('wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-test.tsv -q')\n",
        "os.system('wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-validation.tsv -q')\n",
        "\n",
        "gap_dev = pd.read_csv('gap-development.tsv', delimiter='\\t')\n",
        "gap_val = pd.read_csv('gap-validation.tsv', delimiter='\\t')\n",
        "gap_test = pd.read_csv('gap-test.tsv', delimiter='\\t')\n",
        "\n",
        "print(\"Training data has\", len(gap_dev), \"records.\")\n",
        "print(\"Validation data has\", len(gap_val), \"records.\")\n",
        "print(\"Test data has\", len(gap_test), \"records.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data has 2000 records.\n",
            "Validation data has 454 records.\n",
            "Test data has 2000 records.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LScigRBtWdvS",
        "outputId": "7cf8912e-f050-4e9c-a19c-afaffc355bf1"
      },
      "source": [
        "all_data = pd.concat([gap_dev, winograd_train, gap_val, winograd_val,  winograd_test])\n",
        "all_data = all_data.reset_index(drop=True)\n",
        "print(\"Dataset contains\", len(all_data),\"records\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset contains 3582 records\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yox6XOl3il49"
      },
      "source": [
        "## Download pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrNPYngI3Bxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "d2b6e1209d6c45349e7fd9f5a35e3aab",
            "332bea19350c479f9499cdb2b41a3b49",
            "9410c0b0e8a44db79b8bc9ebeae04738",
            "a014b7927ee641dc9b2f6505b5b6a14c",
            "42a4ed62f3564979a7ac3e5ac9a1a07c",
            "871dc95eb0ae424d8417a3a26fe2b037",
            "045b8cc8e4024a45b7c1e57142785aab",
            "c3899e5e3b7242ff99144c85370b9fef",
            "aacbe678df7c40ac95c1b1f6cbfc1775",
            "3151dfcf0d2b4e3c9eb318606e7a5f07",
            "2172e6af276841aea9b6a19ed4cb6bc1",
            "53965f3d6e7a40e1b547bee5ac3719fa",
            "8ca47750d3f64a36951ee8a4a96f59d1",
            "9510b14501264bde9886620c687b5867",
            "869ad79d12754745a0bbf631dde8f3e0",
            "723a97bf711d44df913f338e5c2e7047",
            "4cdf0d97c60d47a6b25e5748563e2339",
            "4d26beb49a084ba08929e59ca0bafabd",
            "866eb0a75bf84e958ec8c1ba9301a2db",
            "e0525b20c289424c9828404f2dde2315",
            "b621278be4f9440f91bd410441a62466",
            "8c508104f93640d38971517aa8bd75f7",
            "7beaa0c7176047a4946fe03ee9e85e61",
            "27ecf9dbdbbe4caba9031502604b876a",
            "dad18441d20a4964baa180426ef6bb59",
            "d94d3d63e77040cfb2054699b54db8da",
            "39bb0949d0c54514a2c045f0f5559dc8",
            "18812da6dea549c7adbe514ba67b0097",
            "1201329896b0412da963b67f5f6061a6",
            "cea86daba2bb458f826d216d64b46a30",
            "1287b00f9a9f4277aeabd10e7633addb",
            "8575cd4d55ce427cb5cb7f8f9ed427bf"
          ]
        },
        "outputId": "241a9a03-7241-46c5-e88e-c638201ea4c3"
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, WordpieceTokenizer\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "######## hyper-parameters tuning ######\n",
        "# BERT_NAME = 'bert-large-uncased'\n",
        "# BERT_NAME = 'roberta-large'\n",
        "BERT_NAME = 'nielsr/coref-roberta-large'\n",
        "BERT_SIZE = 1024  \n",
        "SEED = 23\n",
        "L = 5\n",
        "S_DIM = 32\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # If model is BERT\n",
        "# tokenizer = BertTokenizer.from_pretrained(BERT_NAME)\n",
        "# bert = BertModel.from_pretrained(BERT_NAME).cuda()\n",
        "# bert = bert.to(device)\n",
        "\n",
        "# # If model is RoBERTa\n",
        "# tokenizer = RobertaTokenizer.from_pretrained(BERT_NAME)\n",
        "# bert = RobertaModel.from_pretrained(BERT_NAME, output_hidden_states=True).cuda()\n",
        "\n",
        "# If model is CorefBERT or CorefRoBERTa\n",
        "bert = AutoModel.from_pretrained(BERT_NAME, output_hidden_states= True).cuda()\n",
        "tokenizer = AutoTokenizer.from_pretrained(BERT_NAME)\n",
        "bert = bert.to(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2b6e1209d6c45349e7fd9f5a35e3aab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=474.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aacbe678df7c40ac95c1b1f6cbfc1775",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425950275.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cdf0d97c60d47a6b25e5748563e2339",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dad18441d20a4964baa180426ef6bb59",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7DQqrPo5pND"
      },
      "source": [
        "## Pooling with Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rYhciBG1XZx",
        "outputId": "59b86657-642c-4c17-9c71-86bf667fd67b"
      },
      "source": [
        "def bert_tokenize(text, p, a, b, p_offset, a_offset, b_offset):\n",
        "    idxs = {}\n",
        "    tokens = []\n",
        "    \n",
        "    a_span = [a_offset, a_offset+len(a), 'a']\n",
        "    b_span = [b_offset, b_offset+len(b), 'b']\n",
        "    p_span = [p_offset, p_offset+len(p), 'p']\n",
        "    \n",
        "    spans = [a_span, b_span, p_span]\n",
        "    spans = sorted(spans, key=lambda x: x[0])\n",
        "    \n",
        "    last_offset = 0\n",
        "    idx = -1\n",
        "    \n",
        "    def token_part(string):\n",
        "        _idxs = []\n",
        "        nonlocal idx\n",
        "        for w in tokenizer.tokenize(string):\n",
        "            idx += 1\n",
        "            tokens.append(w)\n",
        "            _idxs.append(idx)\n",
        "        return _idxs\n",
        "    \n",
        "    \n",
        "    for span in spans:\n",
        "        token_part(text[last_offset:span[0]])\n",
        "        idxs[span[2]] = token_part(text[span[0]:span[1]])\n",
        "        last_offset = span[1]\n",
        "    token_part(text[last_offset:])\n",
        "    return tokens, idxs\n",
        "    \n",
        "\n",
        "print('tokenize...')\n",
        "_ = all_data.apply(lambda x: bert_tokenize(x['Text'], x['Pronoun'], x['A'], x['B'], x['Pronoun-offset'], x['A-offset'], x['B-offset']), axis=1)\n",
        "all_data['encode'] = [tokenizer.convert_tokens_to_ids(i[0]) for i in _]\n",
        "all_data['p_idx'] = [i[1]['p'] for i in _]\n",
        "all_data['a_idx'] = [i[1]['a'] for i in _]\n",
        "all_data['b_idx'] = [i[1]['b'] for i in _]\n",
        "\n",
        "\n",
        "class GPTData(Dataset):\n",
        "    \n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        _ = self.data.loc[idx]\n",
        "        sample = {'id': _['ID'],\n",
        "                  'encode': torch.LongTensor([101] + _['encode'] + [102]),\n",
        "                  'p_idx': torch.LongTensor(_['p_idx'])+1,\n",
        "                  'a_idx': torch.LongTensor(_['a_idx'])+1,\n",
        "                  'b_idx': torch.LongTensor(_['b_idx'])+1,\n",
        "                  'coref': torch.LongTensor([0 if _['A-coref'] else 1 if _['B-coref'] else 2])\n",
        "                 }\n",
        "        return sample\n",
        "        \n",
        "class SortLenSampler(Sampler):\n",
        "    \n",
        "    def __init__(self, data_source, key):\n",
        "        self.sorted_idx = sorted(range(len(data_source)), key=lambda x: len(data_source[x][key]))\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return iter(self.sorted_idx)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sorted_idx)\n",
        "        \n",
        "\n",
        "def gpt_collate_func(x):\n",
        "    _ = [[], [], [], [], [], []]\n",
        "    for i in x:\n",
        "        _[0].append(i['encode'])\n",
        "        _[1].append(i['p_idx'])\n",
        "        _[2].append(i['a_idx'])\n",
        "        _[3].append(i['b_idx'])\n",
        "        _[4].append(i['coref'])\n",
        "        _[5].append(i['id'])\n",
        "    return torch.nn.utils.rnn.pad_sequence(_[0], batch_first=True, padding_value=0), \\\n",
        "           torch.nn.utils.rnn.pad_sequence(_[1], batch_first=True, padding_value=-1), \\\n",
        "           torch.nn.utils.rnn.pad_sequence(_[2], batch_first=True, padding_value=-1), \\\n",
        "           torch.nn.utils.rnn.pad_sequence(_[3], batch_first=True, padding_value=-1), \\\n",
        "           torch.cat(_[4], dim=0), _[5]\n",
        "\n",
        "def meanpooling(x, idx, pad=-1):\n",
        "    \"\"\"x: Layer X Seq X Feat, idx: Seq \"\"\"\n",
        "    t_type = torch.cuda.FloatTensor if isinstance(x, torch.cuda.FloatTensor) else torch.FloatTensor\n",
        "    \n",
        "    _ = torch.zeros((x.shape[0], x.shape[2]))\n",
        "    cnt = 0\n",
        "    for i in idx:\n",
        "        if i == pad:\n",
        "            break\n",
        "        for j in range(x.shape[0]):\n",
        "            _[j] += x[j,i,:]\n",
        "        cnt += 1\n",
        "    if cnt == 0:\n",
        "        raise ValueError('0 dive')\n",
        "    return _/cnt\n",
        "\n",
        "def maxpooling(x, idx, pad=-1):\n",
        "  \"\"\"x: Layer X Seq X Feat, idx: Seq\"\"\"\n",
        "  t_type = torch.cuda.FloatTensor if isinstance(x, torch.cuda.FloatTensor) else torch.FloatTensor\n",
        "  _ = torch.full((x.shape[0], x.shape[2]), -float('inf'))\n",
        "  for i in idx:\n",
        "      if i == pad:\n",
        "          break\n",
        "      for j in range(x.shape[0]):\n",
        "          for k in range(x.shape[2]):\n",
        "              _[j][k] = torch.max(_[j][k], x[j,i,:][k])\n",
        "  \n",
        "  return _\n",
        "\n",
        "\n",
        "def minpooling(x, idx, pad=-1):\n",
        "  \"\"\"x: Layer X Seq X Feat, idx: Seq\"\"\"\n",
        "  t_type = torch.cuda.FloatTensor if isinstance(x, torch.cuda.FloatTensor) else torch.FloatTensor\n",
        "  _ = torch.full((x.shape[0], x.shape[2]), float('inf'))\n",
        "  for i in idx:\n",
        "      if i == pad:\n",
        "          break\n",
        "      for j in range(x.shape[0]):\n",
        "          for k in range(x.shape[2]):\n",
        "              _[j][k] = torch.min(_[j][k], x[j,i,:][k])\n",
        "  \n",
        "  return _\n",
        "\n",
        "\n",
        "def get_span_tensor(bert_t, index, last_layer=L, pad_id=-1):\n",
        "    \"\"\"return Seq X Layer X Feat\"\"\"\n",
        "    span_tensor = []\n",
        "    for i in index:\n",
        "        if i == pad_id:\n",
        "            break\n",
        "        span_tensor.append(bert_t[-last_layer:, i, :])\n",
        "    return torch.stack(span_tensor)\n",
        "    \n",
        "_ = GPTData(all_data)\n",
        "gpt_iter = DataLoader(_, batch_size=5, sampler=SortLenSampler(_, 'encode'), collate_fn=gpt_collate_func)\n",
        "\n",
        "bert_feats = []\n",
        "print('extract bert features..')\n",
        "bert.eval()\n",
        "for (x, p, a, b, y, id_) in gpt_iter:\n",
        "    r = bert.forward(x.cuda(), attention_mask= (x!=0).cuda())\n",
        "    # _ = torch.stack(r[0][-L:]).cpu().data.clone() ## For BERT - last L layers\n",
        "    # _ = torch.stack(r[2][-L:]).cpu().data.clone() ## For RoBERTa - last L layers\n",
        "    # _ = torch.stack([r[0][-1]] + [r[0][0]]).cpu().data.clone() ## top+bottom\n",
        "    _ = torch.stack(r[2][16:21]).cpu().data.clone() ## Layer 16-20\n",
        "    del(r)\n",
        "    for i, v in enumerate(id_):\n",
        "        bert_feats.append({'a': get_span_tensor(_[:,i,:],a[i]),\n",
        "                           'b': get_span_tensor(_[:,i,:],b[i]),\n",
        "                           'p': meanpooling(_[:,i,:], p[i]),\n",
        "                           'ap': (a[i][0] - p[i][0]).type(torch.FloatTensor),\n",
        "                           'bp': (b[i][0] - p[i][0]).type(torch.FloatTensor),\n",
        "                           'y': y[i],\n",
        "                           'id': v})\n",
        "\n",
        "print('extract bert features finished.')       \n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "\n",
        "############\n",
        "\n",
        "class BERTfeature(Dataset):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "def bert_collate_func(x):\n",
        "    _ = [[] for i in range(6)]\n",
        "    for i in x:\n",
        "        _[0].append(i['a'])\n",
        "        _[1].append(i['b'])\n",
        "        _[2].append(i['p'])\n",
        "        _[3].append(i['y'])\n",
        "        _[4].append(i['ap'])\n",
        "        _[5].append(i['bp'])\n",
        "    return [pad_sequence(v, batch_first=True) if i < 2 else torch.stack(v) for i, v in enumerate(_)]\n",
        "\n",
        "############\n",
        "\n",
        "test = [i for i in bert_feats if 'test' in i['id']]\n",
        "train = [i for i in bert_feats if 'test' not in i['id']]\n",
        "\n",
        "######## model define\n",
        "def get_mask(t, shape=(8,123), padding_value=0):\n",
        "    \"\"\"input padded batch input B X Seq X Layer X Feats, output mask with shape BXMask \"\"\"\n",
        "    if padding_value != 0:\n",
        "        raise ValueError\n",
        "    padding_value = torch.zeros(shape)\n",
        "    if t.is_cuda:\n",
        "        padding_value = padding_value.cuda()\n",
        "    mask = []\n",
        "    for i in t:\n",
        "        _ = torch.zeros(i.shape[0])\n",
        "        if t.is_cuda:\n",
        "            _ = _.cuda()\n",
        "        for j in range(i.shape[0]):\n",
        "            if (i[j] == padding_value).sum()==shape[0]*shape[1]:\n",
        "                break\n",
        "            _[j] = 1\n",
        "        mask.append(_)\n",
        "    return torch.stack(mask)\n",
        "\n",
        "def masked_softmax(vec, mask, dim=1, epsilon=1e-15):\n",
        "    exps = torch.exp(vec)\n",
        "    masked_exps = exps * mask\n",
        "    masked_sums = masked_exps.sum(dim, keepdim=True) + epsilon\n",
        "    return masked_exps/masked_sums\n",
        "\n",
        "\n",
        "class AttentionSimilarityLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, hidden_dim, dropout=0.3):\n",
        "        super(AttentionSimilarityLayer, self).__init__()\n",
        "        self.ffnn = nn.Linear(hidden_dim*5, S_DIM)\n",
        "        nn.init.kaiming_normal_(self.ffnn.weight)\n",
        "        self.ln = nn.LayerNorm(hidden_dim, elementwise_affine=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.repr_dropout = nn.Dropout(0.4)\n",
        "        self.rescale = 1/np.sqrt(hidden_dim)\n",
        "\n",
        "    def forward(self, a, a_mask, b, b_mask, p):\n",
        "        a = self.ln(a)\n",
        "        b = self.ln(b)\n",
        "        a_s = (self.repr_dropout(a) @ p[:,:,None]) * self.rescale\n",
        "        b_s = (self.repr_dropout(b) @ p[:,:,None]) * self.rescale\n",
        "        a_attn = masked_softmax(a_s.squeeze(2), a_mask, dim=1)\n",
        "        b_attn = masked_softmax(b_s.squeeze(2), b_mask, dim=1)\n",
        "        a = (a * a_attn[:,:,None]).sum(1)\n",
        "        b = (b * b_attn[:,:,None]).sum(1)\n",
        "        _input = torch.cat([p, a, b, p*a, p*b], dim=1)\n",
        "        y = self.ffnn(self.dropout(_input))\n",
        "\n",
        "        return y\n",
        "    \n",
        "\n",
        "class MSnet(nn.Module):\n",
        "    \n",
        "    def __init__(self, hidden_dim, dropout=0.5, hidden_layer=4):\n",
        "        super(MSnet, self).__init__()\n",
        "        self.sim_layers = nn.ModuleList([AttentionSimilarityLayer(hidden_dim, dropout=dropout) for i in range(hidden_layer)])\n",
        "        self.bn = nn.BatchNorm1d(S_DIM*hidden_layer)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.mention_score = nn.Linear(S_DIM*hidden_layer+2, 3)\n",
        "        self.dist_ecoding = nn.Linear(1,1)\n",
        "        \n",
        "    def forward(self, a, b, p, ap, bp):\n",
        "        y = []\n",
        "        a_mask = get_mask(a, shape=a.shape[2:])\n",
        "        b_mask = get_mask(b, shape=b.shape[2:])\n",
        "        for i, l in enumerate(self.sim_layers):\n",
        "            y.append(l(a[:,:,i,:], a_mask, b[:,:,i,:], b_mask, p[:,i,:]))\n",
        "        y = torch.cat(y, dim=1) # B X 64*Layer\n",
        "        y = self.dropout(self.bn(y).relu())\n",
        "        ap = self.dist_ecoding(ap[:,None]).tanh()\n",
        "        bp = self.dist_ecoding(bp[:,None]).tanh()\n",
        "        return self.mention_score(torch.cat([y, ap, bp], dim=1))\n",
        "\n",
        "\n",
        "def training_cuda(epoch, model, lossfunc, optimizer, train_iter, val_iter, test_iter, start=5):\n",
        "    best_score = 10\n",
        "    for i in range(epoch):\n",
        "        model.train()\n",
        "        epoch_score = np.array([])\n",
        "        for (a, b, p, y, ap, bp) in iter(train_iter):\n",
        "            model.zero_grad()\n",
        "            pred = model.forward(a.cuda(), b.cuda(), p.cuda(), ap.cuda(), bp.cuda())\n",
        "            # loss = lossfunc(pred, y.cuda()) + l2 * torch.stack([torch.norm(i[1]) for i in model.named_parameters() if 'weight' in i[0]]).sum()\n",
        "            loss = lossfunc(pred, y.cuda())\n",
        "            s = score(pred.softmax(1), y.cuda())\n",
        "            epoch_score = np.append(epoch_score, s.cpu().data.numpy())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            model.zero_grad()\n",
        "            val_score =  np.array([])\n",
        "            for (va, vb, vp, vy, vap, vbp) in val_iter:\n",
        "                vpred = model.forward(va.cuda(), vb.cuda(), vp.cuda(), vap.cuda(), vbp.cuda())\n",
        "                vs = score(vpred.softmax(1), vy.cuda())\n",
        "                val_score = np.append(val_score, vs.cpu().data.numpy())\n",
        "            print('epcoh {:02} - train_score {:.4f} - val_score {:.4f} '.format(\n",
        "                                i, np.mean(epoch_score), np.mean(val_score)))\n",
        "            if  np.mean(val_score) < best_score:\n",
        "                best_score = np.mean(val_score)\n",
        "                if i > start:\n",
        "                    torch.save(model.state_dict(), 'tmp.m')\n",
        "    model.load_state_dict(torch.load('tmp.m'))\n",
        "    test_pred = np.array([])\n",
        "    for (ta, tb, tp, ty, tap, tbp) in test_iter:\n",
        "        vpred = model.forward(ta.cuda(), tb.cuda(), tp.cuda(), tap.cuda(), tbp.cuda())\n",
        "        test_pred = np.append(test_pred, vpred.softmax(1).cpu().data.numpy())\n",
        "    return best_score, test_pred\n",
        "\n",
        "\n",
        "def score(pred, y):\n",
        "    t_float = torch.FloatTensor\n",
        "    if isinstance(pred, torch.cuda.FloatTensor):\n",
        "        t_float = torch.cuda.FloatTensor\n",
        "    y = (torch.cumsum(torch.ones(y.shape[0], 3), dim=1) -1).type(t_float) == y[:,None].type(t_float)\n",
        "    s = (y.type(t_float) * pred).sum(1).log()\n",
        "    return -s\n",
        "\n",
        "#####################\n",
        "\n",
        "print('training')\n",
        "m = MSnet(BERT_SIZE, dropout=0.4, hidden_layer=L).cuda()\n",
        "optimizer = optim.Adam(m.parameters(), lr=3e-4, weight_decay=1e-5)\n",
        "loss_fuc = nn.CrossEntropyLoss()\n",
        "batch_size = 32\n",
        "\n",
        "kfold = KFold(n_splits=5, random_state=SEED, shuffle=True)\n",
        "scores = []\n",
        "m_s = deepcopy(m.state_dict().copy())\n",
        "opt_s = deepcopy(optimizer.state_dict().copy())\n",
        "\n",
        "k_th = 0\n",
        "test_iter = DataLoader(BERTfeature(test), batch_size=batch_size, shuffle=False, collate_fn=bert_collate_func)\n",
        "test_preds = []\n",
        "\n",
        "for train_idx, val_idx in kfold.split(list(range(len(train)))):\n",
        "    \n",
        "    _train = [v for i, v in enumerate(train) if i in train_idx]\n",
        "    _val = [v for i, v in enumerate(train) if i in val_idx]\n",
        "    train_iter = DataLoader(BERTfeature(_train), batch_size=batch_size, shuffle=True, collate_fn=bert_collate_func)\n",
        "    val_iter = DataLoader(BERTfeature(_val), batch_size=batch_size, shuffle=False, collate_fn=bert_collate_func)\n",
        "    \n",
        "    m.load_state_dict(m_s)\n",
        "    optimizer.load_state_dict(opt_s)\n",
        "    s, y = training_cuda(30, m, loss_fuc, optimizer, train_iter, val_iter, test_iter)\n",
        "    scores.append(s)\n",
        "    test_preds.append(y)\n",
        "    \n",
        "    k_th += 1\n",
        "    print('------------'*3)\n",
        "    \n",
        "print('Score: {:.4f} {:.4f}'.format(np.mean(scores), np.std(scores)))\n",
        "probs = np.mean(test_preds, axis=0).reshape((-1, 3))\n",
        "true = torch.cat([ty for (ta, tb, tp, ty, tap, tbp) in test_iter], dim=0).data.numpy()\n",
        "t_ids = [i['id'] for i in test]\n",
        "print(log_loss(true, probs))\n",
        "\n",
        "## Accuracy\n",
        "acc_pred = []\n",
        "for i in range(len(probs)):\n",
        "    acc_pred.append(list(probs[i]).index(max(probs[i])))\n",
        "acc_pred = np.asarray(acc_pred)\n",
        "\n",
        "print(\"Accuracy:\",accuracy_score(true, acc_pred))\n",
        "print(\"F1 score:\",f1_score(true, acc_pred, average=None))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenize...\n",
            "extract bert features..\n",
            "extract bert features finished.\n",
            "training\n",
            "epcoh 00 - train_score 0.9553 - val_score 0.9108 \n",
            "epcoh 01 - train_score 0.7742 - val_score 0.7379 \n",
            "epcoh 02 - train_score 0.6633 - val_score 0.6232 \n",
            "epcoh 03 - train_score 0.5705 - val_score 0.5519 \n",
            "epcoh 04 - train_score 0.5008 - val_score 0.5186 \n",
            "epcoh 05 - train_score 0.4563 - val_score 0.4600 \n",
            "epcoh 06 - train_score 0.4146 - val_score 0.4563 \n",
            "epcoh 07 - train_score 0.3828 - val_score 0.4396 \n",
            "epcoh 08 - train_score 0.3584 - val_score 0.4091 \n",
            "epcoh 09 - train_score 0.3311 - val_score 0.4161 \n",
            "epcoh 10 - train_score 0.3125 - val_score 0.4059 \n",
            "epcoh 11 - train_score 0.3041 - val_score 0.4042 \n",
            "epcoh 12 - train_score 0.2724 - val_score 0.4005 \n",
            "epcoh 13 - train_score 0.2595 - val_score 0.4004 \n",
            "epcoh 14 - train_score 0.2360 - val_score 0.4051 \n",
            "epcoh 15 - train_score 0.2571 - val_score 0.3954 \n",
            "epcoh 16 - train_score 0.2369 - val_score 0.3991 \n",
            "epcoh 17 - train_score 0.2349 - val_score 0.4054 \n",
            "epcoh 18 - train_score 0.2196 - val_score 0.3938 \n",
            "epcoh 19 - train_score 0.2014 - val_score 0.3946 \n",
            "epcoh 20 - train_score 0.2034 - val_score 0.4085 \n",
            "epcoh 21 - train_score 0.1756 - val_score 0.4149 \n",
            "epcoh 22 - train_score 0.1853 - val_score 0.4036 \n",
            "epcoh 23 - train_score 0.1559 - val_score 0.4150 \n",
            "epcoh 24 - train_score 0.1775 - val_score 0.4052 \n",
            "epcoh 25 - train_score 0.1719 - val_score 0.4056 \n",
            "epcoh 26 - train_score 0.1535 - val_score 0.4223 \n",
            "epcoh 27 - train_score 0.1542 - val_score 0.4332 \n",
            "epcoh 28 - train_score 0.1437 - val_score 0.4344 \n",
            "epcoh 29 - train_score 0.1428 - val_score 0.4391 \n",
            "------------------------------------\n",
            "epcoh 00 - train_score 0.9641 - val_score 0.8945 \n",
            "epcoh 01 - train_score 0.7743 - val_score 0.7333 \n",
            "epcoh 02 - train_score 0.6533 - val_score 0.6329 \n",
            "epcoh 03 - train_score 0.5658 - val_score 0.5499 \n",
            "epcoh 04 - train_score 0.4959 - val_score 0.4972 \n",
            "epcoh 05 - train_score 0.4521 - val_score 0.4478 \n",
            "epcoh 06 - train_score 0.4107 - val_score 0.4139 \n",
            "epcoh 07 - train_score 0.3828 - val_score 0.4061 \n",
            "epcoh 08 - train_score 0.3583 - val_score 0.4103 \n",
            "epcoh 09 - train_score 0.3365 - val_score 0.3755 \n",
            "epcoh 10 - train_score 0.3252 - val_score 0.4053 \n",
            "epcoh 11 - train_score 0.3020 - val_score 0.3747 \n",
            "epcoh 12 - train_score 0.2862 - val_score 0.3743 \n",
            "epcoh 13 - train_score 0.2572 - val_score 0.3659 \n",
            "epcoh 14 - train_score 0.2578 - val_score 0.3790 \n",
            "epcoh 15 - train_score 0.2414 - val_score 0.3808 \n",
            "epcoh 16 - train_score 0.2389 - val_score 0.3667 \n",
            "epcoh 17 - train_score 0.2231 - val_score 0.3724 \n",
            "epcoh 18 - train_score 0.2157 - val_score 0.3844 \n",
            "epcoh 19 - train_score 0.2104 - val_score 0.3802 \n",
            "epcoh 20 - train_score 0.1921 - val_score 0.3779 \n",
            "epcoh 21 - train_score 0.1845 - val_score 0.3809 \n",
            "epcoh 22 - train_score 0.2008 - val_score 0.3828 \n",
            "epcoh 23 - train_score 0.1694 - val_score 0.3974 \n",
            "epcoh 24 - train_score 0.1508 - val_score 0.3978 \n",
            "epcoh 25 - train_score 0.1636 - val_score 0.4196 \n",
            "epcoh 26 - train_score 0.1645 - val_score 0.3884 \n",
            "epcoh 27 - train_score 0.1515 - val_score 0.4083 \n",
            "epcoh 28 - train_score 0.1455 - val_score 0.4041 \n",
            "epcoh 29 - train_score 0.1479 - val_score 0.4071 \n",
            "------------------------------------\n",
            "epcoh 00 - train_score 0.9517 - val_score 0.9000 \n",
            "epcoh 01 - train_score 0.7675 - val_score 0.7440 \n",
            "epcoh 02 - train_score 0.6465 - val_score 0.6315 \n",
            "epcoh 03 - train_score 0.5627 - val_score 0.5765 \n",
            "epcoh 04 - train_score 0.5002 - val_score 0.5175 \n",
            "epcoh 05 - train_score 0.4512 - val_score 0.4956 \n",
            "epcoh 06 - train_score 0.3971 - val_score 0.4673 \n",
            "epcoh 07 - train_score 0.3825 - val_score 0.4503 \n",
            "epcoh 08 - train_score 0.3390 - val_score 0.4335 \n",
            "epcoh 09 - train_score 0.3347 - val_score 0.4339 \n",
            "epcoh 10 - train_score 0.3086 - val_score 0.4295 \n",
            "epcoh 11 - train_score 0.2919 - val_score 0.4284 \n",
            "epcoh 12 - train_score 0.2767 - val_score 0.4229 \n",
            "epcoh 13 - train_score 0.2467 - val_score 0.4279 \n",
            "epcoh 14 - train_score 0.2337 - val_score 0.4342 \n",
            "epcoh 15 - train_score 0.2297 - val_score 0.4328 \n",
            "epcoh 16 - train_score 0.2165 - val_score 0.4422 \n",
            "epcoh 17 - train_score 0.2228 - val_score 0.4402 \n",
            "epcoh 18 - train_score 0.1947 - val_score 0.4314 \n",
            "epcoh 19 - train_score 0.1942 - val_score 0.4377 \n",
            "epcoh 20 - train_score 0.1803 - val_score 0.4471 \n",
            "epcoh 21 - train_score 0.1739 - val_score 0.4514 \n",
            "epcoh 22 - train_score 0.1732 - val_score 0.4514 \n",
            "epcoh 23 - train_score 0.1601 - val_score 0.4544 \n",
            "epcoh 24 - train_score 0.1656 - val_score 0.4609 \n",
            "epcoh 25 - train_score 0.1569 - val_score 0.4657 \n",
            "epcoh 26 - train_score 0.1467 - val_score 0.4782 \n",
            "epcoh 27 - train_score 0.1313 - val_score 0.4784 \n",
            "epcoh 28 - train_score 0.1303 - val_score 0.4836 \n",
            "epcoh 29 - train_score 0.1415 - val_score 0.4894 \n",
            "------------------------------------\n",
            "epcoh 00 - train_score 0.9547 - val_score 0.9058 \n",
            "epcoh 01 - train_score 0.7558 - val_score 0.7411 \n",
            "epcoh 02 - train_score 0.6417 - val_score 0.6267 \n",
            "epcoh 03 - train_score 0.5613 - val_score 0.5380 \n",
            "epcoh 04 - train_score 0.5000 - val_score 0.4953 \n",
            "epcoh 05 - train_score 0.4460 - val_score 0.4694 \n",
            "epcoh 06 - train_score 0.4123 - val_score 0.4578 \n",
            "epcoh 07 - train_score 0.3860 - val_score 0.4260 \n",
            "epcoh 08 - train_score 0.3538 - val_score 0.4166 \n",
            "epcoh 09 - train_score 0.3249 - val_score 0.4031 \n",
            "epcoh 10 - train_score 0.3123 - val_score 0.4058 \n",
            "epcoh 11 - train_score 0.2902 - val_score 0.3984 \n",
            "epcoh 12 - train_score 0.2820 - val_score 0.4040 \n",
            "epcoh 13 - train_score 0.2532 - val_score 0.4403 \n",
            "epcoh 14 - train_score 0.2524 - val_score 0.4006 \n",
            "epcoh 15 - train_score 0.2325 - val_score 0.4089 \n",
            "epcoh 16 - train_score 0.2354 - val_score 0.4172 \n",
            "epcoh 17 - train_score 0.2224 - val_score 0.4067 \n",
            "epcoh 18 - train_score 0.2139 - val_score 0.4114 \n",
            "epcoh 19 - train_score 0.2005 - val_score 0.4181 \n",
            "epcoh 20 - train_score 0.1965 - val_score 0.4328 \n",
            "epcoh 21 - train_score 0.1812 - val_score 0.4357 \n",
            "epcoh 22 - train_score 0.1841 - val_score 0.4205 \n",
            "epcoh 23 - train_score 0.1669 - val_score 0.4351 \n",
            "epcoh 24 - train_score 0.1770 - val_score 0.4401 \n",
            "epcoh 25 - train_score 0.1677 - val_score 0.4407 \n",
            "epcoh 26 - train_score 0.1469 - val_score 0.4586 \n",
            "epcoh 27 - train_score 0.1483 - val_score 0.4416 \n",
            "epcoh 28 - train_score 0.1434 - val_score 0.4632 \n",
            "epcoh 29 - train_score 0.1321 - val_score 0.4560 \n",
            "------------------------------------\n",
            "epcoh 00 - train_score 0.9559 - val_score 0.9075 \n",
            "epcoh 01 - train_score 0.7710 - val_score 0.7126 \n",
            "epcoh 02 - train_score 0.6543 - val_score 0.6055 \n",
            "epcoh 03 - train_score 0.5553 - val_score 0.5488 \n",
            "epcoh 04 - train_score 0.5021 - val_score 0.4977 \n",
            "epcoh 05 - train_score 0.4410 - val_score 0.4706 \n",
            "epcoh 06 - train_score 0.4021 - val_score 0.4534 \n",
            "epcoh 07 - train_score 0.3762 - val_score 0.4337 \n",
            "epcoh 08 - train_score 0.3517 - val_score 0.4286 \n",
            "epcoh 09 - train_score 0.3240 - val_score 0.4380 \n",
            "epcoh 10 - train_score 0.3064 - val_score 0.4226 \n",
            "epcoh 11 - train_score 0.3031 - val_score 0.4442 \n",
            "epcoh 12 - train_score 0.2768 - val_score 0.4331 \n",
            "epcoh 13 - train_score 0.2709 - val_score 0.4520 \n",
            "epcoh 14 - train_score 0.2428 - val_score 0.4422 \n",
            "epcoh 15 - train_score 0.2287 - val_score 0.4403 \n",
            "epcoh 16 - train_score 0.2195 - val_score 0.4418 \n",
            "epcoh 17 - train_score 0.2195 - val_score 0.4436 \n",
            "epcoh 18 - train_score 0.2108 - val_score 0.4388 \n",
            "epcoh 19 - train_score 0.1983 - val_score 0.4409 \n",
            "epcoh 20 - train_score 0.1914 - val_score 0.4471 \n",
            "epcoh 21 - train_score 0.1867 - val_score 0.4709 \n",
            "epcoh 22 - train_score 0.1799 - val_score 0.4836 \n",
            "epcoh 23 - train_score 0.1582 - val_score 0.4850 \n",
            "epcoh 24 - train_score 0.1776 - val_score 0.4933 \n",
            "epcoh 25 - train_score 0.1582 - val_score 0.4760 \n",
            "epcoh 26 - train_score 0.1532 - val_score 0.5292 \n",
            "epcoh 27 - train_score 0.1399 - val_score 0.4844 \n",
            "epcoh 28 - train_score 0.1401 - val_score 0.5077 \n",
            "epcoh 29 - train_score 0.1296 - val_score 0.5098 \n",
            "------------------------------------\n",
            "Score: 0.4007 0.0212\n",
            "0.3898961255651171\n",
            "Accuracy: 0.8297872340425532\n",
            "F1 score: [0.83448276 0.82783883 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}